name: MLOps Pipeline

on:
  push:
    branches:
      - walid
  pull_request:
    branches:
      - walid

jobs:
  pipeline:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.8'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install gdown  # Required to download from Google Drive

    - name: Download dataset from Google Drive
      run: |
        echo "Downloading dataset from Google Drive..."
        gdown --id ${{ secrets.GDRIVE_FILE_ID }} --output dataset.zip || { echo "Failed to download dataset from Google Drive"; exit 1; }

        echo "Unzipping dataset..."
        unzip dataset.zip -d dataset_raw || { echo "Failed to unzip dataset"; exit 1; }

        echo "Extracted structure:"
        find dataset_raw

        # Move train and test folders to expected location
        mkdir -p dataset/train dataset/test

        # Move the train folder and its contents
        mv dataset_raw/data_doxaria/dataset/train dataset/train || echo "::error::Train folder not found"

        # Move the test folder and its contents
        mv dataset_raw/data_doxaria/dataset/test dataset/test || echo "::error::Test folder not found"

        echo "Dataset organized into 'dataset/train' and 'dataset/test'"

    - name: Verify dataset access
      run: |
        echo "Checking dataset directory..."
        ls -la dataset
        ls -la dataset/train || echo "::error::Train folder missing"
        ls -la dataset/test || echo "::error::Test folder missing"

    - name: Run pipeline
      run: python pipeline1/run_pipeline.py
      env:
        DATASET_DIR: dataset
