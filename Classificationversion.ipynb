{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jK7VG120KHoN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation terminée avec succès.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Définir les chemins des dossiers\n",
    "base_dir = r\"C:\\Users\\Ons\\Downloads\\dataset_2\\dataset\"  # Dossier principal de ton dataset\n",
    "output_dir = r\"C:\\Users\\Ons\\Downloads\\dataset_output\"  # Dossier où seront stockées les images divisées\n",
    "\n",
    "# Fonction pour lister les images et leurs labels (classes)\n",
    "def list_images_from_dir(base_dir):\n",
    "    image_paths = []\n",
    "    image_labels = []\n",
    "    for label in os.listdir(base_dir):  # Liste des sous-dossiers (classes)\n",
    "        label_dir = os.path.join(base_dir, label)\n",
    "        if os.path.isdir(label_dir):  # Vérifier que c'est bien un dossier\n",
    "            for img_file in os.listdir(label_dir):  # Liste des fichiers dans chaque sous-dossier\n",
    "                if img_file.endswith(('.jpg', '.png')):  # Vérifier que ce sont bien des images\n",
    "                    image_paths.append(os.path.join(label_dir, img_file))\n",
    "                    image_labels.append(label)\n",
    "    return image_paths, image_labels\n",
    "\n",
    "# Liste les images et leurs labels dans le dossier `train`\n",
    "train_dir = os.path.join(base_dir, 'train')  # Ton dossier train\n",
    "test_dir = os.path.join(base_dir, 'test')  # Ton dossier test\n",
    "train_images, train_labels = list_images_from_dir(train_dir)\n",
    "\n",
    "# Diviser les images en 80% train, 10% validation, 10% test\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, stratify=train_labels, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, stratify=y_val, random_state=42)\n",
    "\n",
    "# Créer la structure des dossiers pour le split (train, val, test)\n",
    "os.makedirs(os.path.join(output_dir, 'train', 'others'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'train', 'ordonnance'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'train', 'bulletin_de_soin'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'val', 'others'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'val', 'ordonnance'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'val', 'bulletin_de_soin'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'test', 'others'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'test', 'ordonnance'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'test', 'bulletin_de_soin'), exist_ok=True)\n",
    "\n",
    "# Fonction pour copier les images dans le bon dossier\n",
    "def copy_images(image_paths, image_labels, split_type):\n",
    "    for img_path, label in zip(image_paths, image_labels):\n",
    "        # Définir le chemin de destination\n",
    "        dest_dir = os.path.join(output_dir, split_type, label)\n",
    "        shutil.copy(img_path, dest_dir)  # Copier l'image dans le dossier correspondant\n",
    "\n",
    "# Copier les images dans les sous-dossiers train, val, test\n",
    "copy_images(X_train, y_train, 'train')\n",
    "copy_images(X_val, y_val, 'val')\n",
    "copy_images(X_test, y_test, 'test')\n",
    "\n",
    "print(\"Séparation terminée avec succès.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ons\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\ons\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\ons\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\ons\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ons\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1315 images belonging to 3 classes.\n",
      "Found 164 images belonging to 3 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m 5111808/83683744\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:49\u001b[0m 8us/step"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 41\u001b[0m\n\u001b[0;32m     33\u001b[0m val_generator \u001b[38;5;241m=\u001b[39m val_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     34\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m),  \u001b[38;5;66;03m# Dossier validation\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(img_size, img_size),\n\u001b[0;32m     36\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     37\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     38\u001b[0m )\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Charger le modèle Xception pré-entraîné (sans la couche de classification finale)\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m base_model \u001b[38;5;241m=\u001b[39m Xception(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m, include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m(img_size, img_size, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Geler les poids du modèle de base pour ne pas les réentraîner\u001b[39;00m\n\u001b[0;32m     44\u001b[0m base_model\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\applications\\xception.py:325\u001b[0m, in \u001b[0;36mXception\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[0;32m    318\u001b[0m         weights_path \u001b[38;5;241m=\u001b[39m file_utils\u001b[38;5;241m.\u001b[39mget_file(\n\u001b[0;32m    319\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxception_weights_tf_dim_ordering_tf_kernels.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    320\u001b[0m             WEIGHTS_PATH,\n\u001b[0;32m    321\u001b[0m             cache_subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    322\u001b[0m             file_hash\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0a58e3b7378bc2990ea3b43d5981f1f6\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    323\u001b[0m         )\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m         weights_path \u001b[38;5;241m=\u001b[39m file_utils\u001b[38;5;241m.\u001b[39mget_file(\n\u001b[0;32m    326\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxception_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    327\u001b[0m             WEIGHTS_PATH_NO_TOP,\n\u001b[0;32m    328\u001b[0m             cache_subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    329\u001b[0m             file_hash\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb0042744bf5b25fce3cb969f33bebb97\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    330\u001b[0m         )\n\u001b[0;32m    331\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights_path)\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\file_utils.py:311\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir, force_download)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m         urlretrieve(origin, download_target, DLProgbar())\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmsg))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:268\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reporthook:\n\u001b[0;32m    266\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[1;32m--> 268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m block \u001b[38;5;241m:=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(bs):\n\u001b[0;32m    269\u001b[0m     read \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(block)\n\u001b[0;32m    270\u001b[0m     tfp\u001b[38;5;241m.\u001b[39mwrite(block)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Paramètres\n",
    "img_size = 299  # Xception nécessite des images de taille 299x299\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Création de générateurs d'images pour la data augmentation et la normalisation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalisation des pixels\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Préparer les générateurs d'images pour les données d'entraînement et de validation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'train'),  # Dossier train où les images sont stockées\n",
    "    target_size=(img_size, img_size),  # Redimensionner les images à la taille Xception\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # Les étiquettes sont dans plusieurs classes\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'val'),  # Dossier validation\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Charger le modèle Xception pré-entraîné (sans la couche de classification finale)\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Geler les poids du modèle de base pour ne pas les réentraîner\n",
    "base_model.trainable = False\n",
    "\n",
    "# Ajouter une nouvelle tête de réseau (couches de classification)\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')  # 3 classes : others, ordonnance, bulletin_de_soin\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Sauvegarder le modèle entraîné\n",
    "model.save(\"xception_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2794 images belonging to 3 classes.\n",
      "Found 164 images belonging to 3 classes.\n",
      "Found 165 images belonging to 3 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ons\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 7s/step - accuracy: 0.7199 - loss: 0.6876 - val_accuracy: 0.9268 - val_loss: 0.2085\n",
      "Epoch 2/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m688s\u001b[0m 8s/step - accuracy: 0.9254 - loss: 0.2616 - val_accuracy: 0.9695 - val_loss: 0.1193\n",
      "Epoch 3/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m587s\u001b[0m 7s/step - accuracy: 0.9347 - loss: 0.2125 - val_accuracy: 0.9756 - val_loss: 0.0941\n",
      "Epoch 4/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m598s\u001b[0m 7s/step - accuracy: 0.9403 - loss: 0.1904 - val_accuracy: 0.9573 - val_loss: 0.1100\n",
      "Epoch 5/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 6s/step - accuracy: 0.9517 - loss: 0.1569 - val_accuracy: 0.9512 - val_loss: 0.1106\n",
      "Epoch 6/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1453s\u001b[0m 17s/step - accuracy: 0.9509 - loss: 0.1579 - val_accuracy: 0.9573 - val_loss: 0.0937\n",
      "Epoch 7/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 6s/step - accuracy: 0.9488 - loss: 0.1563 - val_accuracy: 0.9634 - val_loss: 0.0829\n",
      "Epoch 8/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m526s\u001b[0m 6s/step - accuracy: 0.9495 - loss: 0.1351 - val_accuracy: 0.9817 - val_loss: 0.0668\n",
      "Epoch 9/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 6s/step - accuracy: 0.9596 - loss: 0.1268 - val_accuracy: 0.9634 - val_loss: 0.0892\n",
      "Epoch 10/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 7s/step - accuracy: 0.9582 - loss: 0.1213 - val_accuracy: 0.9817 - val_loss: 0.0583\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4s/step - accuracy: 0.9455 - loss: 0.0940\n",
      "Test Accuracy: 0.9576\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Définir les chemins des dossiers\n",
    "base_dir = r\"C:\\Users\\Ons\\Downloads\\dataset_2\\dataset\"  # Dossier principal de ton dataset\n",
    "output_dir = r\"C:\\Users\\Ons\\Downloads\\dataset_output\"  # Dossier où seront stockées les images divisées\n",
    "\n",
    "# Fonction pour lister les images et leurs labels (classes)\n",
    "def list_images_from_dir(base_dir):\n",
    "    image_paths = []\n",
    "    image_labels = []\n",
    "    for label in os.listdir(base_dir):  # Liste des sous-dossiers (classes)\n",
    "        label_dir = os.path.join(base_dir, label)\n",
    "        if os.path.isdir(label_dir):  # Vérifier que c'est bien un dossier\n",
    "            for img_file in os.listdir(label_dir):  # Liste des fichiers dans chaque sous-dossier\n",
    "                if img_file.endswith(('.jpg', '.png')):  # Vérifier que ce sont bien des images\n",
    "                    image_paths.append(os.path.join(label_dir, img_file))\n",
    "                    image_labels.append(label)\n",
    "    return image_paths, image_labels\n",
    "\n",
    "# Liste les images et leurs labels dans le dossier `train`\n",
    "train_dir = os.path.join(base_dir, 'train')  # Ton dossier train\n",
    "test_dir = os.path.join(base_dir, 'test')  # Ton dossier test\n",
    "train_images, train_labels = list_images_from_dir(train_dir)\n",
    "\n",
    "# Diviser les images en 80% train, 10% validation, 10% test\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, stratify=train_labels, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, stratify=y_val, random_state=42)\n",
    "\n",
    "# Prétraitement des images avec ImageDataGenerator\n",
    "img_size = 299  # Taille d'entrée de Xception (299x299)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'val'),\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'test'),\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Charger le modèle Xception pré-entraîné\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Geler les couches du modèle pour éviter de les réentraîner\n",
    "base_model.trainable = False\n",
    "\n",
    "# Ajouter une couche de classification\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(3, activation='softmax')  # Nombre de classes (3 dans ton cas)\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Évaluer sur les données de test\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sauvegarder le modèle après l'entraînement\n",
    "model.save('mon_modele.keras')  # Sauvegarde du modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000018EDE2A3920> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000018EDE2A3920> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Prédiction : [[0.00592459 0.11845969 0.8756157 ]]\n",
      "Nom de la classe prédite : Other\n",
      "Classe prédite : [2]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# 1. Charger ton modèle pré-entraîné\n",
    "model = tf.keras.models.load_model('mon_modele.keras')  # Remplace par le chemin vers ton modèle sauvegardé\n",
    "\n",
    "# 2. Charger et pré-traiter l'image à tester\n",
    "img_path = r'C:\\Users\\Ons\\Documents\\696278-fond-noir-texture-gratuit-vectoriel.jpg'  # Remplace par le chemin vers l'image à tester\n",
    "\n",
    "img = image.load_img(img_path, target_size=(299, 299))  # Taille conforme au modèle Xception\n",
    "\n",
    "# Convertir l'image en tableau numpy\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "# Ajouter une dimension pour le batch (1, 299, 299, 3)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Normaliser l'image\n",
    "img_array = img_array / 255.0\n",
    "\n",
    "# Faire la prédiction\n",
    "prediction = model.predict(img_array)\n",
    "print(f\"Prédiction : {prediction}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Afficher le nom de la classe prédite\n",
    "predicted_class = np.argmax(prediction, axis=1)  # Indice de la classe prédite\n",
    "predicted_class_name = class_names[predicted_class[0]]  # Nom de la classe\n",
    "print(f\"Nom de la classe prédite : {predicted_class_name}\")\n",
    "print(f\"Classe prédite : {predicted_class}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bulletin_de_soin', 'Ordonnance', 'Other']\n"
     ]
    }
   ],
   "source": [
    "# Afficher les noms des classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ENTRE ESSAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2794 images belonging to 3 classes.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: 'C:\\\\Users\\\\Ons\\\\Downloads\\\\dataset_2\\\\dataset\\\\val'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m\n\u001b[0;32m     17\u001b[0m test_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m     19\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     20\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     21\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(img_size, img_size),\n\u001b[0;32m     22\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     23\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     24\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m val_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     27\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     28\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(img_size, img_size),\n\u001b[0;32m     29\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     30\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     33\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     34\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     35\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(img_size, img_size),\n\u001b[0;32m     36\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     37\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     38\u001b[0m )\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Charger le modèle Xception pré-entraîné\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1138\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1122\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1137\u001b[0m ):\n\u001b[1;32m-> 1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1139\u001b[0m         directory,\n\u001b[0;32m   1140\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1141\u001b[0m         target_size\u001b[38;5;241m=\u001b[39mtarget_size,\n\u001b[0;32m   1142\u001b[0m         color_mode\u001b[38;5;241m=\u001b[39mcolor_mode,\n\u001b[0;32m   1143\u001b[0m         keep_aspect_ratio\u001b[38;5;241m=\u001b[39mkeep_aspect_ratio,\n\u001b[0;32m   1144\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m   1145\u001b[0m         class_mode\u001b[38;5;241m=\u001b[39mclass_mode,\n\u001b[0;32m   1146\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format,\n\u001b[0;32m   1147\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1148\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m   1149\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m   1150\u001b[0m         save_to_dir\u001b[38;5;241m=\u001b[39msave_to_dir,\n\u001b[0;32m   1151\u001b[0m         save_prefix\u001b[38;5;241m=\u001b[39msave_prefix,\n\u001b[0;32m   1152\u001b[0m         save_format\u001b[38;5;241m=\u001b[39msave_format,\n\u001b[0;32m   1153\u001b[0m         follow_links\u001b[38;5;241m=\u001b[39mfollow_links,\n\u001b[0;32m   1154\u001b[0m         subset\u001b[38;5;241m=\u001b[39msubset,\n\u001b[0;32m   1155\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m   1156\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1157\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:453\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    452\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(directory)):\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    455\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: 'C:\\\\Users\\\\Ons\\\\Downloads\\\\dataset_2\\\\dataset\\\\val'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Définir les chemins des dossiers\n",
    "base_dir = r\"C:\\Users\\Ons\\Downloads\\dataset_2\\dataset\"\n",
    "output_dir = r\"C:\\Users\\Ons\\Downloads\\dataset_output\"\n",
    "\n",
    "# Prétraitement des images avec ImageDataGenerator\n",
    "img_size = 299  # Taille d'entrée de Xception (299x299)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(base_dir, 'train'),\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    os.path.join(base_dir, 'val'),\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(base_dir, 'test'),\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Charger le modèle Xception pré-entraîné\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Geler les couches du modèle pour éviter de les réentraîner\n",
    "base_model.trainable = False\n",
    "\n",
    "# Ajouter des couches personnalisées pour la classification\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(3, activation='softmax')  # 3 classes\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# **Première phase d'entraînement** : avec les couches gelées\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# **Fine-Tuning** : On dégèle les dernières couches du modèle Xception\n",
    "base_model.trainable = True\n",
    "\n",
    "# **Débloquer seulement les dernières couches**\n",
    "for layer in base_model.layers[:-10]:  # Geler toutes les couches sauf les 10 dernières\n",
    "    layer.trainable = False\n",
    "\n",
    "# **Recompiler avec un plus petit taux d'apprentissage**\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),  # LR plus petit\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# **Deuxième phase d'entraînement** : avec fine-tuning sur les couches dégivrées\n",
    "history_finetuned = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# **Évaluer sur les données de test**\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# **Sauvegarder le modèle fine-tuné**\n",
    "model.save('mon_modele_finetuned.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autre essai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Séparation des données terminée !\n",
      "Found 1315 images belonging to 3 classes.\n",
      "Found 1644 images belonging to 3 classes.\n",
      "Found 573 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ons\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 14s/step - accuracy: 0.8353 - loss: 0.2931 - val_accuracy: 0.9939 - val_loss: 0.0258\n",
      "Epoch 2/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m678s\u001b[0m 16s/step - accuracy: 0.9944 - loss: 0.0262 - val_accuracy: 0.9854 - val_loss: 0.0416\n",
      "Epoch 3/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m767s\u001b[0m 18s/step - accuracy: 0.9954 - loss: 0.0139 - val_accuracy: 0.9824 - val_loss: 0.0499\n",
      "Epoch 4/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m696s\u001b[0m 17s/step - accuracy: 0.9942 - loss: 0.0137 - val_accuracy: 0.9976 - val_loss: 0.0152\n",
      "Epoch 5/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m705s\u001b[0m 17s/step - accuracy: 0.9906 - loss: 0.0219 - val_accuracy: 0.9945 - val_loss: 0.0130\n",
      "Epoch 6/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m700s\u001b[0m 17s/step - accuracy: 0.9948 - loss: 0.0129 - val_accuracy: 0.9945 - val_loss: 0.0127\n",
      "Epoch 7/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m698s\u001b[0m 17s/step - accuracy: 0.9992 - loss: 0.0051 - val_accuracy: 0.9964 - val_loss: 0.0092\n",
      "Epoch 8/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m697s\u001b[0m 17s/step - accuracy: 0.9974 - loss: 0.0097 - val_accuracy: 0.9957 - val_loss: 0.0199\n",
      "Epoch 9/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m690s\u001b[0m 17s/step - accuracy: 0.9938 - loss: 0.0231 - val_accuracy: 0.9976 - val_loss: 0.0074\n",
      "Epoch 10/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m695s\u001b[0m 17s/step - accuracy: 0.9965 - loss: 0.0093 - val_accuracy: 0.9982 - val_loss: 0.0050\n",
      "Epoch 1/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m748s\u001b[0m 18s/step - accuracy: 0.8068 - loss: 0.5512 - val_accuracy: 0.9957 - val_loss: 0.0104\n",
      "Epoch 2/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m736s\u001b[0m 18s/step - accuracy: 0.9744 - loss: 0.0489 - val_accuracy: 0.9915 - val_loss: 0.0185\n",
      "Epoch 3/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m752s\u001b[0m 18s/step - accuracy: 0.9844 - loss: 0.0451 - val_accuracy: 0.9909 - val_loss: 0.0214\n",
      "Epoch 4/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m743s\u001b[0m 18s/step - accuracy: 0.9785 - loss: 0.0397 - val_accuracy: 0.9897 - val_loss: 0.0270\n",
      "Epoch 5/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 14s/step - accuracy: 0.9944 - loss: 0.0264 - val_accuracy: 0.9915 - val_loss: 0.0235\n",
      "Epoch 6/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 14s/step - accuracy: 0.9915 - loss: 0.0230 - val_accuracy: 0.9945 - val_loss: 0.0175\n",
      "Epoch 7/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m580s\u001b[0m 14s/step - accuracy: 0.9931 - loss: 0.0164 - val_accuracy: 0.9939 - val_loss: 0.0196\n",
      "Epoch 8/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m571s\u001b[0m 14s/step - accuracy: 0.9932 - loss: 0.0194 - val_accuracy: 0.9945 - val_loss: 0.0173\n",
      "Epoch 9/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m572s\u001b[0m 14s/step - accuracy: 0.9963 - loss: 0.0202 - val_accuracy: 0.9945 - val_loss: 0.0149\n",
      "Epoch 10/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 14s/step - accuracy: 0.9951 - loss: 0.0143 - val_accuracy: 0.9945 - val_loss: 0.0142\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 6s/step - accuracy: 0.9879 - loss: 0.0265\n",
      "✅ Test Accuracy: 0.9895\n",
      "✔ Modèle sauvegardé avec succès !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 📌 1. Définir les chemins\n",
    "base_dir = r\"C:\\Users\\Ons\\Downloads\\dataset_2\\dataset\"\n",
    "output_dir = r\"C:\\Users\\Ons\\Downloads\\dataset_output\"\n",
    "\n",
    "# 📌 2. Fonction pour lister les images et leurs classes\n",
    "def list_images_from_dir(directory):\n",
    "    image_paths = []\n",
    "    image_labels = []\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Le dossier {directory} n'existe pas !\")\n",
    "        return [], []\n",
    "\n",
    "    for label in os.listdir(directory):\n",
    "        label_dir = os.path.join(directory, label)\n",
    "        if os.path.isdir(label_dir):\n",
    "            for img_file in os.listdir(label_dir):\n",
    "                if img_file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                    image_paths.append(os.path.join(label_dir, img_file))\n",
    "                    image_labels.append(label)\n",
    "    return image_paths, image_labels\n",
    "\n",
    "# 📌 3. Vérifier l'existence des dossiers et recréer si nécessaire\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for category in ['others', 'ordonnance', 'bulletin_de_soin']:\n",
    "        os.makedirs(os.path.join(output_dir, split, category), exist_ok=True)\n",
    "\n",
    "# 📌 4. Charger les images et labels\n",
    "train_images, train_labels = list_images_from_dir(os.path.join(base_dir, 'train'))\n",
    "\n",
    "# 📌 5. Diviser les images (80% train, 10% val, 10% test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(train_images, train_labels, test_size=0.2, stratify=train_labels, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# 📌 6. Copier les images dans les nouveaux dossiers\n",
    "def copy_images(image_paths, image_labels, split_type):\n",
    "    for img_path, label in zip(image_paths, image_labels):\n",
    "        dest_dir = os.path.join(output_dir, split_type, label)\n",
    "        shutil.copy(img_path, dest_dir)\n",
    "\n",
    "copy_images(X_train, y_train, 'train')\n",
    "copy_images(X_val, y_val, 'val')\n",
    "copy_images(X_test, y_test, 'test')\n",
    "\n",
    "print(\"✔ Séparation des données terminée !\")\n",
    "\n",
    "# 📌 7. Définir les générateurs de données\n",
    "img_size = 299\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'train'),\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'val'),\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'test'),\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# 📌 8. Charger le modèle Xception pré-entraîné\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "base_model.trainable = False  # On gèle les couches du modèle\n",
    "\n",
    "# 📌 9. Construire le modèle final\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(3, activation='softmax')  # 3 classes : others, ordonnance, bulletin_de_soin\n",
    "])\n",
    "\n",
    "# 📌 10. Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 📌 11. Première phase d'entraînement (avec couches gelées)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 📌 12. Fine-tuning : dégeler les 10 dernières couches de Xception\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-10]:  \n",
    "    layer.trainable = False\n",
    "\n",
    "# 📌 13. Recompiler avec un plus petit taux d'apprentissage\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 📌 14. Deuxième phase d'entraînement (fine-tuning)\n",
    "history_finetuned = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 📌 15. Évaluation sur les données de test\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"✅ Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 📌 16. Sauvegarder le modèle\n",
    "model.save('mon_modele_finetuned.keras')\n",
    "print(\"✔ Modèle sauvegardé avec succès !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Modèle chargé avec succès !\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Charger le modèle sauvegardé\n",
    "model = load_model('mon_modele_finetuned.keras')\n",
    "print(\"✔ Modèle chargé avec succès !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "✅ Prédiction : others\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Définir la taille de l'image attendue par le modèle\n",
    "img_size = 299  \n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_size, img_size))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Ajouter une dimension batch\n",
    "    img_array /= 255.  # Normalisation\n",
    "    return img_array\n",
    "\n",
    "# Exemple d'image à tester\n",
    "image_path = r\"C:\\Users\\Ons\\Downloads\\doxaria\\doxaria\\042ef63e-ccb0-4397-8b32-081b725badcc.png\"\n",
    "img_array = preprocess_image(image_path)\n",
    "\n",
    "# Faire une prédiction\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions)  # Récupérer la classe avec la probabilité max\n",
    "\n",
    "# Définir les classes en fonction du training\n",
    "class_names = ['others', 'ordonnance', 'bulletin_de_soin']\n",
    "\n",
    "# Afficher la prédiction\n",
    "print(f\"✅ Prédiction : {class_names[predicted_class]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autre essai 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 📌 1. Définir les chemins\n",
    "output_dir = r\"C:\\Users\\Ons\\Downloads\\dataset_output\"\n",
    "\n",
    "# 📌 2. Paramètres\n",
    "img_size = 300\n",
    "batch_size = 32\n",
    "num_classes = 3  # others, ordonnance, bulletin_de_soin\n",
    "\n",
    "# 📌 3. Définir les générateurs de données\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'train'),\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'val'),\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'test'),\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# 📌 4. Charger EfficientNetB3 (FULL TRAINABLE dès le départ)\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "base_model.trainable = True  # 🔥 On entraîne tout dès le départ\n",
    "\n",
    "# 📌 5. Construire le modèle\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.BatchNormalization(),  # 📌 Stabilisation\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.4),  # 📌 Réduction du surajustement\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(num_classes, activation='softmax')  # 3 classes\n",
    "])\n",
    "\n",
    "# 📌 6. Compiler le modèle\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 📌 7. Callbacks pour optimiser l'entraînement\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)\n",
    "checkpoint = ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n",
    "\n",
    "# 📌 8. Entraînement du modèle (UNE SEULE PHASE)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  # 🔹 Max 20 epochs, mais stoppé automatiquement si nécessaire\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 📌 9. Charger le meilleur modèle et évaluer\n",
    "model.load_weights(\"best_model.keras\")\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"✅ Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 📌 10. Sauvegarde du modèle final\n",
    "model.save('efficientnetb3_final.keras')\n",
    "print(\"✔ Modèle sauvegardé avec succès !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
